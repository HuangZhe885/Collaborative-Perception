<img width="70%" alt="WechatIMG208" src="https://user-images.githubusercontent.com/44192081/232229514-6dacfb34-fc74-4fe9-947d-2cf08f75b7f6.png">

# AEV2V: Accurate and Efficient Vehicle-to-Vehicle Collaborative Perception

![WechatIMG207](https://user-images.githubusercontent.com/44192081/232229563-7e5027a7-9db9-4ffc-8d34-a8b6a73d9de8.jpeg)

Multi-agent collaborative perception could significantly upgrade the perception performance by enabling agents to share information with each other through communication.However, duplicated data sharing and high communication overhead remain significant barriers to real-time communication for autonomous driving. 
<img width="70%" alt="WechatIMG206" src="https://user-images.githubusercontent.com/44192081/232229359-c2b8907d-31c9-4fd3-984b-0c153b6927ca.png">

Using spatially sparse depth information can reduce the amount of shared data, however the compressed depth features are sparse and low-resolution, resulting in inadequate fusion across multi-agents and unstable bounding boxes, leading in classification and regression misalignment.As a result, we present a sparse perception framework for fusing multi-agent features while decreasing communication traffic, keeping complementary features for complete fusion, enhancing the stability of bounding boxes, and reducing classification and regression misalignment.  Extensive experimental results demonstrate that AEV2V  sets new state-of-the-art performance for 3D object detection and achieves robust performance even under harsh, noisy environments.


https://user-images.githubusercontent.com/44192081/232229098-8d5a62a6-ac25-4e82-95ee-00d89994eec3.mp4


